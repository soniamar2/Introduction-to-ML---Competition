{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soniamar2/Introduction-to-ML---Competition/blob/main/vit_slow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-TJfOzN4u4u"
      },
      "source": [
        "## Libraries & config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsXUI5NFaPa4",
        "outputId": "11f90783-b217-496b-bca4-47caa7eb1128"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/disi/miniconda3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch, time, os, copy, random, imageio, os, shutil, zipfile, tarfile, timm\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, ConcatDataset, Dataset\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from torchvision.transforms import v2\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import AutoAugmentPolicy, InterpolationMode\n",
        "\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "\n",
        "import json # to be removed\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFAXadwf4u42"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNC9PXjDaPa_"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Set the seed\n",
        "seed = 47\n",
        "set_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgbF5sAP4u43"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k03e8h0F4u43"
      },
      "outputs": [],
      "source": [
        "#Non-editable hyper-parameters\n",
        "\n",
        "#Num_class = 196 #FOR AIRCRAFT\n",
        "im_dimention = 224\n",
        "layer_width = 512\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Editable hyper-parameters\n",
        "\n",
        "num_epochs = 20 # 160 in original\n",
        "batches = 32\n",
        "val_split = 0.2 #DO NOT TOUCH UNLESS DRAMA HAPPENS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVkbShVF4u43"
      },
      "source": [
        "## Dataset & Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-y-t57jaPbA"
      },
      "outputs": [],
      "source": [
        "class DatasetManager:\n",
        "    def __init__(self, dataset_dir, train_dir='train', test_dir='test'):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.train_dir = os.path.join(dataset_dir, train_dir)\n",
        "        self.test_dir = os.path.join(dataset_dir, test_dir)\n",
        "\n",
        "    def handle_dataset(self, source):\n",
        "        if os.path.isfile(source):\n",
        "            self._handle_local_file(source)\n",
        "        else:\n",
        "            raise ValueError(\"Only local files are supported in this setup\")\n",
        "\n",
        "    def _handle_local_file(self, source):\n",
        "        if source.endswith('.zip'):\n",
        "            self._extract_zip(source)\n",
        "        elif source.endswith('.tar') or source.endswith('.tar.gz'):\n",
        "            self._extract_tar(source)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file format\")\n",
        "\n",
        "    def _extract_zip(self, filepath):\n",
        "        with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "            zip_ref.extractall(self.dataset_dir)\n",
        "        self._correct_directory_structure()\n",
        "\n",
        "    def _extract_tar(self, filepath):\n",
        "        with tarfile.open(filepath, 'r') as tar_ref:\n",
        "            tar_ref.extractall(self.dataset_dir)\n",
        "        self._correct_directory_structure()\n",
        "\n",
        "    def _correct_directory_structure(self):\n",
        "        extracted_folders = [name for name in os.listdir(self.dataset_dir) if os.path.isdir(os.path.join(self.dataset_dir, name))]\n",
        "        if len(extracted_folders) == 1:\n",
        "            extracted_main_dir = os.path.join(self.dataset_dir, extracted_folders[0])\n",
        "            for item in os.listdir(extracted_main_dir):\n",
        "                shutil.move(os.path.join(extracted_main_dir, item), self.dataset_dir)\n",
        "            os.rmdir(extracted_main_dir)\n",
        "\n",
        "    def prepare_dataloaders(self, batch_size=batches, val_split=val_split, random_state=42):\n",
        "        # Define transforms\n",
        "        data_transforms = {\n",
        "        'train': v2.Compose([\n",
        "            v2.Resize((244,244)),\n",
        "            v2.RandomRotation(15,),\n",
        "            v2.RandomCrop(im_dimention),\n",
        "            #v2.RandomRotation(15,),\n",
        "            #v2.ColorJitter(brightness=0.2,  #bad picture conditions (e.g. surveillance cameras)\n",
        "            #               contrast=0.2,     # poor visibility (e.g. underwater images)\n",
        "            #               saturation=0.2,\n",
        "            #               hue=0.1),\n",
        "            v2.RandomHorizontalFlip(),\n",
        "            v2.ToTensor(),\n",
        "            v2.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]),\n",
        "            #v2.RandomErasing(p=0.1)\n",
        "        ]),\n",
        "        'valid': v2.Compose([\n",
        "            v2.Resize((im_dimention,im_dimention)),\n",
        "            v2.ToTensor(),\n",
        "            v2.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "        ]),\n",
        "        'test': v2.Compose([\n",
        "            v2.Resize((im_dimention,im_dimention)),\n",
        "            v2.ToTensor(),\n",
        "            v2.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "        # Load train and validation datasets\n",
        "        image_datasets = {'train': datasets.ImageFolder(self.train_dir, data_transforms['train'])}\n",
        "\n",
        "        # Split the train dataset into train and validation\n",
        "        train_dataset = image_datasets['train']\n",
        "        train_size = int((1 - val_split) * len(train_dataset))\n",
        "        val_size = len(train_dataset) - train_size\n",
        "        train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "        image_datasets['valid'] = val_dataset\n",
        "\n",
        "        # Load test dataset without class subfolders\n",
        "        image_datasets['test'] = CustomImageDataset(self.test_dir, transform=data_transforms['test'])\n",
        "\n",
        "        # Create dataloaders\n",
        "        dataloaders = {\n",
        "            'train': DataLoader(train_dataset, batch_size=batches, shuffle=True, num_workers=4),\n",
        "            'valid': DataLoader(val_dataset, batch_size=batches, shuffle=False, num_workers=4),\n",
        "            'test': DataLoader(image_datasets['test'], batch_size=batches, shuffle=False, num_workers=4)\n",
        "        }\n",
        "\n",
        "        dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid', 'test']}\n",
        "\n",
        "        return dataloaders, dataset_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLtCgy_IaPbB"
      },
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if fname.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        class_id = os.path.basename(img_path).split('_')[0]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, class_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lj2LFz44u44"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC9rP0HY4u44"
      },
      "outputs": [],
      "source": [
        "# dataloader\n",
        "dataset_manager = DatasetManager('/home/disi/COMPETITION_DATASET')\n",
        "\n",
        "# Specify the path to the zipped dataset\n",
        "dataset_manager.handle_dataset('/home/disi/CAR.zip')\n",
        "\n",
        "dataloaders, dataset_sizes = dataset_manager.prepare_dataloaders()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8wI2H3I4u45"
      },
      "outputs": [],
      "source": [
        "def count_labels_in_train(train_dir):\n",
        "    # List all items in the train directory\n",
        "    items = os.listdir(train_dir)\n",
        "    # Filter out only directories\n",
        "    label_dirs = [item for item in items if os.path.isdir(os.path.join(train_dir, item))]\n",
        "    return len(label_dirs)\n",
        "\n",
        "train_dir_path = '/home/disi/COMPETITION_DATASET/train'\n",
        "Num_class = count_labels_in_train(train_dir_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMi7TTdS4u45"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHBztWsOVPWI"
      },
      "outputs": [],
      "source": [
        "# Early stopping implementation\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, verbose=False):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                if self.verbose:\n",
        "                    print('Early stopping')\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "\n",
        "early_stopping = EarlyStopping(patience=7, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGGNDi1qVPWK"
      },
      "outputs": [],
      "source": [
        "#Train function with checkpoints\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs, checkpoint_path='checkpoint.pth'):\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    scaler = GradScaler()\n",
        "    early_stopping = EarlyStopping(patience=7, verbose=True)\n",
        "\n",
        "    start_epoch = 0\n",
        "\n",
        "    # Load checkpoint if exists\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        print(\"Checkpoint keys:\", checkpoint.keys())\n",
        "        if 'model_state_dict' in checkpoint:\n",
        "            model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "            start_epoch = checkpoint['epoch'] + 1\n",
        "            best_acc = checkpoint['best_acc']\n",
        "            best_model_wts = checkpoint['best_model_wts']\n",
        "            print(f\"Loaded checkpoint '{checkpoint_path}' (epoch {checkpoint['epoch']})\")\n",
        "        else:\n",
        "            print(f\"Checkpoint '{checkpoint_path}' does not contain 'model_state_dict'. Starting from scratch.\")\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    with autocast():\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'valid':\n",
        "                scheduler.step(epoch_loss)\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                early_stopping(epoch_loss, model)\n",
        "\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "\n",
        "        if early_stopping.early_stop:\n",
        "            break\n",
        "\n",
        "        # Save checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'best_acc': best_acc,\n",
        "            'best_model_wts': best_model_wts,\n",
        "        }, checkpoint_path)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60}m {time_elapsed % 60}s')\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8GBaWfZeaPbE",
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "class LabelSmoothingCrossEntropy(nn.Module):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        log_prob = F.log_softmax(input, dim=-1)\n",
        "        weight = input.new_ones(input.size()) * (self.smoothing / (input.size(-1) - 1.))\n",
        "        weight.scatter_(-1, target.unsqueeze(-1), (1. - self.smoothing))\n",
        "        loss = (-weight * log_prob).sum(dim=-1).mean()\n",
        "        return loss\n",
        "\n",
        "criterion = LabelSmoothingCrossEntropy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98paT_XJ4u45"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJRqa6sbaPbG"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the ViT model\n",
        "model_ft = timm.create_model('vit_large_patch16_224', pretrained=True, num_classes=Num_class)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "# Configure the optimizer\n",
        "optimizer_ft = torch.optim.AdamW(model_ft.parameters(), lr=0.003, weight_decay=0.01) #Before: lr = 3e-4 (3.3 times more)\n",
        "\n",
        "# Parameters for warm-up and CosineAnnealingLR\n",
        "num_warmup_steps = 500  # Number of warm-up steps #Before : 500\n",
        "num_training_steps = 15 * len(dataloaders['train'])  # Total number of training steps\n",
        "\n",
        "# Create the combined scheduler\n",
        "scheduler_ft = get_cosine_schedule_with_warmup(\n",
        "    optimizer_ft,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_CAIn14VPWK"
      },
      "outputs": [],
      "source": [
        "# Uncomment if running out of memory\n",
        "\n",
        "#torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNQK5GWhaPbH",
        "outputId": "b5dcfcc4-0ca0-4493-e4f8-cdbb27e8a72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint keys: dict_keys(['epoch', 'model_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'best_acc', 'best_model_wts'])\n",
            "Loaded checkpoint 'checkpoints_vit_CAR_30ephocs_faster' (epoch 0)\n",
            "Training complete in 0.0m 1.5578186511993408s\n",
            "Best val Acc: 0.0037\n"
          ]
        }
      ],
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, scheduler_ft,\n",
        "                       num_epochs=num_epochs,\n",
        "                       checkpoint_path='checkpoints_vit_CAR_30ephocs_faster'\n",
        "                       )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sq6NLFaX4u46"
      },
      "source": [
        "## Final testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GEbLeAKVPWK"
      },
      "outputs": [],
      "source": [
        "def submit(results, url=\"https://competition-production.up.railway.app/results/\"):\n",
        "    res = json.dumps(results)\n",
        "    response = requests.post(url, res)\n",
        "    try:\n",
        "        result = json.loads(response.text)\n",
        "        print(f\"accuracy is {result['accuracy']}\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"ERROR: {response.text}\")\n",
        "\n",
        "\n",
        "def test_model_collect_predictions(dataloaders, model, class_names):\n",
        "    model.eval()\n",
        "    preds = {}\n",
        "\n",
        "    for inputs, image_ids in dataloaders['test']:\n",
        "        inputs = inputs.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        for image_id, pred in zip(image_ids, preds):\n",
        "            preds[image_id] = class_names[pred.item()]\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgRWbKkk4u46"
      },
      "outputs": [],
      "source": [
        "# to be removed the day of the competition\n",
        "\n",
        "def submit__(results, filename=\"results.json\"):\n",
        "    res = json.dumps(results, indent=4)  # Format JSON with indentation for readability\n",
        "    try:\n",
        "        with open(filename, \"w\") as file:\n",
        "            file.write(res)\n",
        "        print(f\"Results saved to {filename}\")\n",
        "    except IOError as e:\n",
        "        print(f\"ERROR: Unable to write to file {filename}. Exception: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XyVYC9z4u46",
        "outputId": "3bd2bb7a-247e-4c18-d2ca-dd2857a398b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to results.json\n"
          ]
        }
      ],
      "source": [
        "class_names = dataloaders['train'].dataset.dataset.classes\n",
        "\n",
        "# Get predictions from the test set\n",
        "preds = test_model_collect_predictions(dataloaders, model_ft, class_names)\n",
        "\n",
        "# Prepare the submission dictionary\n",
        "res = {\n",
        "    \"images\": preds,\n",
        "    \"groupname\": \"Tanos Matadores\"  # Replace with your actual group name\n",
        "}\n",
        "\n",
        "\n",
        "#submit__(res) #Test version\n",
        "submit(res)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}